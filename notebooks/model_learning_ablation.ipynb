{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: This example is compatible with versions v0.2.1dev or higher (i.e., up to date with GitHub). For instructions on how to run with latest pip stable versions (<=v0.1.5), see [this](https://github.com/facebookresearch/mbrl-lib/blob/main/notebooks/pets_example_v0.1.5.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview\n",
    "\n",
    "In this example, we are going to use our toolbox to write the [PETS](https://arxiv.org/pdf/1805.12114.pdf) algorithm (Chua at al., 2018), and use it to solve a continuous version of the cartpole environment. PETS is a model-based algorithm that consists of two main components: an ensemble of probabilistic models (each a feed-forward neural network), and a planner using the [Cross-Entropy Method](https://people.smp.uq.edu.au/DirkKroese/ps/aortut.pdf) (de Boer et al., 2004). \n",
    "\n",
    "A basic implementation of this algorithm consists of the following sequence of steps:\n",
    "\n",
    "1. Gather data using an exploration policy\n",
    "2. Repeat:<br>\n",
    "  2.1. Train the dynamics model using all available data.<br>\n",
    "  2.2. Do a trajectory on the environment, choosing actions with the planner, using the dynamics model to simulate environment transitions.\n",
    "  \n",
    "The ensemble model is trained to predict the environment's dynamics, and the planner tries to find high-reward trajectories over the model dynamics. \n",
    "\n",
    "To implement this using `MBRL-Lib`, we will use an ensemble of neural networks (NNs) modelling Gaussian distributions (available in the [mbrl.models](https://luisenp.github.io/mbrl-lib/models.html#mbrl.models.GaussianMLP) module), and a trajectory optimizer agent that uses CEM (available in the [mbrl.planning](https://luisenp.github.io/mbrl-lib/planning.html#mbrl.planning.TrajectoryOptimizerAgent) module). We will also rely on several of the utilities available in the [mbrl.util](https://luisenp.github.io/mbrl-lib/util.html) module. Finally, we will wrap the dynamics model into a [gym-like environment](https://luisenp.github.io/mbrl-lib/models.html#mbrl.models.ModelEnv) over which we can plan action sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/nvidia-384:/usr/lib/x86_64-linux-gnu/libstdc++.so.6:/private/home/pakamienny/.mujoco/mujoco200/bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pakamienny/anaconda3/envs/srbench/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/private/home/pakamienny/anaconda3/envs/srbench/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/private/home/pakamienny/anaconda3/envs/srbench/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/private/home/pakamienny/anaconda3/envs/srbench/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/private/home/pakamienny/anaconda3/envs/srbench/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/private/home/pakamienny/anaconda3/envs/srbench/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import omegaconf\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import mbrl.env.cartpole_continuous as cartpole_env\n",
    "import mbrl.env.reward_fns as reward_fns\n",
    "import mbrl.env.termination_fns as termination_fns\n",
    "import mbrl.models as models\n",
    "import mbrl.planning as planning\n",
    "import mbrl.util.common as common_util\n",
    "import mbrl.util as util\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d_%m_%Y_%H:%M:%S\")\n",
    "\n",
    "logger = SummaryWriter(\"./runs/\"+dt_string)\n",
    "gravity = 9.8\n",
    "masscart = 1.0\n",
    "masspole = 0.1\n",
    "total_mass = masspole + masscart\n",
    "length = 0.5  # actually half the pole's length\n",
    "polemass_length = masspole * length\n",
    "force_mag = 10.0\n",
    "tau = 0.02 \n",
    "\n",
    "def true_cartpole_transition_fn():\n",
    "    temp = \"({0} * X5 + {1} * X4**2 * sin(X3)) / {2}\".format(force_mag, polemass_length, total_mass)    \n",
    "    thetaacc = \"({0} * sin(X3) - cos(X3) * {1}) / ({2} * (4.0 / 3.0 - {3} *  cos(X3)**2 / {4}))\".format(gravity, temp, length, masspole, total_mass)\n",
    "    xacc = \"{0} - {1} * {2} *  cos(X3) / {3}\".format(temp, polemass_length, thetaacc, total_mass)\n",
    "    functions = []\n",
    "    functions.append(\"X1 + {0} * X2\".format(tau))\n",
    "    functions.append(\"X2 + {0} * {1}\".format(tau, xacc))\n",
    "    functions.append(\"X3 + {0} * X4\".format(tau))\n",
    "    functions.append(\"X4 + {0} * {1}\".format(tau, thetaacc))\n",
    "    return functions\n",
    "\n",
    "\n",
    "\n",
    "mpl.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded on cuda:0!\n",
      "[0]\n",
      "1.5403118231021224\n",
      "((-0.009013905954874757 add (0.0018600155071908455 mul inv((((38.79999999999926 add (-0.03891752075683964 add (0.9991129679403977 mul x_4))) mul ((-47.399999999999075 add (-0.2729999999998257 mul (-0.1270972815378547 add (0.9681081983773678 mul x_3)))) sub (-7.810000000000926 add (2.6100000000030006 mul log((0.0411999999376176 add (0.006960000022335051 mul (-0.0670237752454803 add (1.1572955967767242 mul x_2))))))))) mul (-18.999999999998483 add (-0.03709999999978328 mul sqrt((0.01659999999980314 add (0.0034999999997850327 mul (0.009057918920383304 add (1.139751399964385 mul x_0))))))))))) sub ((-0.005346094045125244 add (-0.020485626648220512 mul (0.0724586584239339 add (0.9762942697752147 mul x_1)))) add (0.005763905954874755 add (-0.877384313795614 mul (0.009057918920383304 add (1.139751399964385 mul x_0))))))\n",
      "[0]\n",
      "2.951706922215024\n",
      "(((0.5516370031694086 mul (-0.03891752075683964 add (0.9991129679403977 mul x_4))) add (((104.66215886280847 add (0.0724586584239339 add (0.9762942697752147 mul x_1))) mul (-0.011527424706166496 add (-0.009963306882585954 mul sin(((((-0.5586135819771085 mul (-0.03891752075683964 add (0.9991129679403977 mul x_4))) sub (5.551032856081393 add (0.030778386987353332 mul (0.009057918920383304 add (1.139751399964385 mul x_0))))) add (0.0937571439918785 add (0.0069098444512531035 mul (0.0724586584239339 add (0.9762942697752147 mul x_1))))) add (-0.7070328559949313 add (1.772960578838192 mul (-0.0670237752454803 add (1.1572955967767242 mul x_2))))))))) mul ((-0.18575859650961188 add (-0.00678728098684195 mul (0.0724586584239339 add (0.9762942697752147 mul x_1)))) sub ((0.18588859650804235 add (0.00361728097385435 mul (0.0724586584239339 add (0.9762942697752147 mul x_1)))) add (-0.8088614035261475 add (0.02234225027531565 mul (-0.1270972815378547 add (0.9681081983773678 mul x_3)))))))) add (0.4787017384924571 add (1.0014054477110959 mul (0.0724586584239339 add (0.9762942697752147 mul x_1)))))\n",
      "[0]\n",
      "1.495668452304499\n",
      "(((0.0028820721954537117 mul (-0.1270972815378547 add (0.9681081983773678 mul x_3))) mul (7.159999967923358 add (-0.051599994991066774 mul sin((-72.10000000163492 add (-0.009779999972283156 mul inv(((-3.4900000000000038 add (-0.0741000000001223 mul (-0.1270972815378547 add (0.9681081983773678 mul x_3)))) add ((-29.7 add (0.3099999999999645 mul (0.0724586584239339 add (0.9762942697752147 mul x_1)))) add ((((0.0015100000000035992 add (8.949999999999992 mul (0.009057918920383304 add (1.139751399964385 mul x_0)))) mul (0.6679999999998574 add (-0.36700000000001265 mul (0.009057918920383304 add (1.139751399964385 mul x_0))))) sub (4.800000000000006 add (0.07409999999997852 mul (-0.03891752075683964 add (0.9991129679403977 mul x_4))))) add (-70.3 add (-0.00602999999997857 mul (-0.03891752075683964 add (0.9991129679403977 mul x_4)))))))))))))) add (0.060539819904125915 add (0.8640834741968917 mul (-0.0670237752454803 add (1.1572955967767242 mul x_2)))))\n",
      "[0]\n",
      "2.3649772263458386\n",
      "((((-2.4526028984531503 add (-4.683388916244403 mul sin((-1.5205991911331977 add (-0.0670237752454803 add (1.1572955967767242 mul x_2)))))) mul ((-0.16296861781035543 add (-3.679541961572311 mul inv((-22.598744870817335 add (-0.03891752075683964 add (0.9991129679403977 mul x_4)))))) mul (-5.935087180442257 add (-0.04977123683874143 mul inv(((1.133436902147919 add (-1.7959652655803853 mul (-0.0670237752454803 add (1.1572955967767242 mul x_2)))) sub (-1.4128369019656406 add (-1.080091630023487 mul abs((0.021472333656436377 add (13.160373857769997 mul (0.0724586584239339 add (0.9762942697752147 mul x_1))))))))))))) sub ((-2.400833466718896 add (4.217688341707002 mul (-0.0670237752454803 add (1.1572955967767242 mul x_2)))) mul (-0.04503802782867073 add (0.004695953869482111 mul cos(((-0.1649794842610636 add (-39.20655131841897 mul (0.009057918920383304 add (1.139751399964385 mul x_0)))) mul (0.09795085968882637 add (-7.428426350863349 mul (-0.1270972815378547 add (0.9681081983773678 mul x_3)))))))))) sub ((-0.1537163070713873 add (-1.0419730724664447 mul (-0.1270972815378547 add (0.9681081983773678 mul x_3)))) sub (0.0957163070556959 add (-0.18491278586957807 mul (-0.03891752075683964 add (0.9991129679403977 mul x_4))))))\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "from mbrl.models.utils_symbolicregressor import expr_to_numexpr_fn\n",
    "fns = true_cartpole_transition_fn()\n",
    "model_path = \"model.pt\" \n",
    "try:\n",
    "    if not os.path.isfile(model_path): \n",
    "        url = \"https://dl.fbaipublicfiles.com/symbolicregression/model1.pt\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(model_path, 'wb').write(r.content)\n",
    "    if not torch.cuda.is_available():\n",
    "        model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        model = torch.load(model_path)\n",
    "        model = model.cuda()\n",
    "    print(\"Model successfully loaded on {}!\".format(model.device))\n",
    "except Exception as e:\n",
    "    print(\"ERROR: model not loaded! path was: {}\".format(model_path))\n",
    "    print(e)    \n",
    "\n",
    "est = symbolicregression.model.SymbolicTransformerRegressor(model=model, max_input_points=200, n_trees_to_refine=10,rescale=True)\n",
    "\n",
    "\n",
    "inputs = np.random.randn(100,5)\n",
    "for fn in fns:\n",
    "    ne_expr = expr_to_numexpr_fn(sp.parse_expr(fn))\n",
    "    outputs = ne_expr(inputs)\n",
    "    est.fit(inputs, outputs)\n",
    "    print(((est.predict(inputs)-outputs)**2).mean())\n",
    "    print(est.retrieve_tree())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the environment\n",
    "\n",
    "First we instantiate the environment and specify which reward function and termination function to use with the gym-like environment wrapper, along with some utility objects. The termination function tells the wrapper if an observation should cause an episode to end or not, and it is an input used in some algorithms, like [MBPO](https://github.com/JannerM/mbpo/blob/master/mbpo/static/halfcheetah.py). The reward function is used to compute the value of the reward given an observation, and it's used by some algorithms, like [PETS](https://github.com/kchua/handful-of-trials/blob/77fd8802cc30b7683f0227c90527b5414c0df34c/dmbrl/controllers/MPC.py#L65)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "env = cartpole_env.CartPoleEnv()\n",
    "env.seed(seed)\n",
    "rng = np.random.default_rng(seed=0)\n",
    "eval_rng = np.random.default_rng(seed=1)\n",
    "\n",
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(seed)\n",
    "obs_shape = env.observation_space.shape\n",
    "act_shape = env.action_space.shape\n",
    "\n",
    "# This functions allows the model to evaluate the true rewards given an observation \n",
    "reward_fn = reward_fns.cartpole\n",
    "# This function allows the model to know if an observation should make the episode end\n",
    "term_fn = termination_fns.cartpole\n",
    "\n",
    "\n",
    "trial_length = 200\n",
    "num_trials = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydra configuration\n",
    "\n",
    "MBRL-Lib uses [Hydra](https://github.com/facebookresearch/hydra) to manage configurations. For the purpose of this example, you can think of the configuration object as a dictionary with key/value pairs--and equivalent attributes--that specify the model and algorithmic options. Our toolbox expects the configuration object to be organized as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded on cuda:0!\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 1\n",
    "\n",
    "\n",
    "import os, requests\n",
    "import symbolicregression\n",
    "model_path = \"model.pt\" \n",
    "try:\n",
    "    if not os.path.isfile(model_path): \n",
    "        url = \"https://dl.fbaipublicfiles.com/symbolicregression/model1.pt\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(model_path, 'wb').write(r.content)\n",
    "    if not torch.cuda.is_available():\n",
    "        model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        model = torch.load(model_path)\n",
    "        model = model.cuda()\n",
    "    print(\"Model successfully loaded on {}!\".format(model.device))\n",
    "except Exception as e:\n",
    "    print(\"ERROR: model not loaded! path was: {}\".format(model_path))\n",
    "    print(e)    \n",
    "    \n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "\n",
    "    \n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\":         \n",
    "    {\n",
    "        \"_target_\": \"mbrl.models.MultiDimensionalRegressorWrapper\",\n",
    "        \"regressor_class\": \"symbolicregression.model.SymbolicTransformerRegressor\",\n",
    "        \"regressor_args\": {\n",
    "                        \"model\": model,\n",
    "                        \"max_input_points\":200,\n",
    "                        \"n_trees_to_refine\":100,\n",
    "                        \"rescale\":True\n",
    "                        },\n",
    "        #\"functions\": true_cartpole_transition_fn(),\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"device\": device\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": False,\n",
    "        \"normalize\": True,\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": -1,\n",
    "        \"validation_ratio\": 0.0\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict, flags={\"allow_objects\": True})\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "model_trainer = models.SymbolicModelTrainer(dynamics_model, tensorboard_logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 1\n",
    "import os\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\":         \n",
    "    {\n",
    "        \"_target_\": \"mbrl.models.MultiDimensionalRegressorWrapper\",\n",
    "        \"regressor_class\": \"operon.sklearn.SymbolicRegressor\",\n",
    "        \"regressor_args\": {\n",
    "                            \"local_iterations\":5,\n",
    "                            \"generations\":10000,\n",
    "                            \"n_threads\": 1,\n",
    "                            \"random_state\":None,\n",
    "                            \"time_limit\":2*60,\n",
    "                            \"max_evaluations\":int(5e5),\n",
    "                            \"population_size\":500,\n",
    "                            \"allowed_symbols\":  'add,sub,mul,div,constant,variable,cos,sin,pow'\n",
    "                            },\n",
    "        #\"functions\": true_cartpole_transition_fn(),\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"device\": device\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": False,\n",
    "        \"normalize\": False,\n",
    "        \"dataset_size\": 1000000\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": -1,\n",
    "        \"validation_ratio\": 0.0\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict)\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "model_trainer = models.SymbolicModelTrainer(dynamics_model,  tensorboard_logger=logger)\n",
    "\n",
    "\n",
    "def train_callback(train_score, eval_score):\n",
    "    return  \"train: {}, eval: {}\".format(train_score, eval_score)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 1\n",
    "\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\":         \n",
    "    {\n",
    "        \"_target_\": \"mbrl.models.MultiDimensionalRegressorWrapper\",\n",
    "        \"regressor_class\": \"operon.sklearn.SymbolicRegressor\",\n",
    "        \"regressor_args\": {\n",
    "                            \"local_iterations\":5,\n",
    "                            \"generations\":10000,\n",
    "                            \"n_threads\": 1,\n",
    "                            \"random_state\":None,\n",
    "                            \"time_limit\":2*60,\n",
    "                            \"max_evaluations\":int(5e5),\n",
    "                            \"population_size\":500,\n",
    "                            \"allowed_symbols\":  'add,sub,mul,div,constant,variable,cos,sin,pow'\n",
    "                            },\n",
    "        #\"functions\": true_cartpole_transition_fn(),\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"device\": device\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": False,\n",
    "        \"normalize\": False,\n",
    "        \"dataset_size\": 1000000\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": -1,\n",
    "        \"validation_ratio\": 0.0\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict)\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "model_trainer = models.SymbolicModelTrainer(dynamics_model,  tensorboard_logger=logger)\n",
    "\n",
    "\n",
    "def train_callback(train_score, eval_score):\n",
    "    return  \"train: {}, eval: {}\".format(train_score, eval_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HROCH import Hroch\n",
    "import os\n",
    "\n",
    "est = Hroch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 1\n",
    "import importlib\n",
    "from pstree.cluster_gp_sklearn import GPRegressor,selTournamentDCD\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS']=\"3\"\n",
    "from sympy import *\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\":         \n",
    "    {\n",
    "        \"_target_\": \"mbrl.models.MultiDimensionalRegressorWrapper\",\n",
    "        \"regressor_class\": \"pstree.cluster_gp_sklearn.PSTreeRegressor\",\n",
    "        \"regressor_args\": {         \n",
    "            \"regr_class\":  GPRegressor,\n",
    "            \"tree_class\": DecisionTreeRegressor,\n",
    "            \"height_limit\":6,\n",
    "            \"n_pop\": 25,\n",
    "             \"n_gen\": 500,\n",
    "             \"normalize\":True, \n",
    "             \"basic_primitive\":'optimal',\n",
    "            \"select\": selTournamentDCD,\n",
    "            \"size_objective\": False,\n",
    "            \"afp\": True      \n",
    "        },\n",
    "        #\"functions\": true_cartpole_transition_fn(),\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"device\": device\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": False,\n",
    "        \"normalize\": False,\n",
    "        \"dataset_size\": 1000000\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": -1,\n",
    "        \"validation_ratio\": 0.0\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict ,flags={\"allow_objects\": True})\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "model_trainer = models.SymbolicModelTrainer(dynamics_model,  tensorboard_logger=logger)\n",
    "\n",
    "\n",
    "def train_callback(train_score, eval_score):\n",
    "    return  \"train: {}, eval: {}\".format(train_score, eval_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 1\n",
    "import importlib\n",
    "from pstree.cluster_gp_sklearn import GPRegressor,selTournamentDCD\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS']=\"3\"\n",
    "from sympy import *\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\":         \n",
    "    {\n",
    "        \"_target_\": \"mbrl.models.MultiDimensionalRegressorWrapper\",\n",
    "        \"regressor_class\": \"gplearn.genetic.SymbolicRegressor\",\n",
    "        \"regressor_args\": {         \n",
    "           \"function_set\": {\n",
    "            'add': lambda x, y : x + y,\n",
    "            'sub': lambda x, y : x - y,\n",
    "            'mul': lambda x, y : x*y,\n",
    "            'div': lambda x, y : x/y,\n",
    "            'sqrt': lambda x : x**0.5,\n",
    "            'log': lambda x : log(x),\n",
    "            'abs': lambda x : abs(x),\n",
    "            'neg': lambda x : -x,\n",
    "            'inv': lambda x : 1/x,\n",
    "            'max': lambda x, y : max(x, y),\n",
    "            'min': lambda x, y : min(x, y),\n",
    "            'sin': lambda x : sin(x),\n",
    "            'cos': lambda x : cos(x),\n",
    "        }\n",
    "        },\n",
    "        #\"functions\": true_cartpole_transition_fn(),\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"device\": device\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": False,\n",
    "        \"normalize\": False,\n",
    "        \"dataset_size\": 1000000\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": -1,\n",
    "        \"validation_ratio\": 0.0\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict ,flags={\"allow_objects\": True})\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "model_trainer = models.SymbolicModelTrainer(dynamics_model,  tensorboard_logger=logger)\n",
    "\n",
    "\n",
    "def train_callback(train_score, eval_score):\n",
    "    return  \"train: {}, eval: {}\".format(train_score, eval_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Note: </b> This example uses a probabilistic ensemble. You can also use a fully deterministic model with class GaussianMLP by setting ensemble_size=1, and deterministic=True. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dynamics model\n",
    "\n",
    "Given the configuration above, the following two lines of code create a wrapper for 1-D transition reward models, and a gym-like environment that wraps it, which we can use for simulating the real environment. The 1-D model wrapper takes care of creating input/output data tensors to the underlying NN model (by concatenating observations, actions and rewards appropriately), normalizing the input data to the model, and other data processing tasks (e.g., converting observation targets to deltas with respect to the input observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gym-like environment to encapsulate the model\n",
    "model_env = models.ModelEnv(env, dynamics_model, term_fn, reward_fn, generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a replay buffer\n",
    "\n",
    "We can create a replay buffer for this environment an configuration using the following method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)\n",
    "eval_replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=eval_rng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples stored (train) 50\n",
      "# samples stored (eval) 10000\n"
     ]
    }
   ],
   "source": [
    "n_train_transitions = 50\n",
    "n_eval_transitions = 10000\n",
    "\n",
    "\n",
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    steps_or_trials_to_collect=n_train_transitions, # initial exploration steps\n",
    "    agent=planning.RandomAgent(env),\n",
    "    agent_kwargs={}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=train_replay_buffer,\n",
    "    trial_length=trial_length, \n",
    "    collect_full_trajectories=False\n",
    ")\n",
    "print(\"# samples stored (train)\", train_replay_buffer.num_stored)\n",
    "\n",
    "\n",
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    steps_or_trials_to_collect=n_eval_transitions, # initial exploration steps\n",
    "    agent=planning.RandomAgent(env),\n",
    "    agent_kwargs={}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=eval_replay_buffer,\n",
    "    trial_length=trial_length, \n",
    "    collect_full_trajectories=False\n",
    "\n",
    ")\n",
    "print(\"# samples stored (eval)\", eval_replay_buffer.num_stored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_397789/257435543.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'add' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled models\n",
      "X0\n",
      "add(add(add(add(X1, mul(X4, X2)), mul(X4, X2)), mul(X4, X2)), mul(X4, X2))\n",
      "X2\n",
      "sub(add(mul(mul(mul(X4, 0.393), 0.393), 0.393), X3), mul(X4, 0.393))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'X0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/srbench/lib/python3.7/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mgetArguments\u001b[0;34m(names, local_dict, global_dict)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_397789/1088401233.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdataset_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/model_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset_train, dataset_val, callback, evaluate, silent, **args)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdataset_train_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mtrain_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/one_dim_tr_model.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, batch, optimizer, target)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     def eval_score(\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/symbolicregressor.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, model_in, optimizer, target, **args)\u001b[0m\n\u001b[1;32m    133\u001b[0m     ):\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/symbolicregressor.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, model_in, target)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     ) -> Tuple[torch.Tensor, Dict[str, Any]]:\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     def sample_propagation_indices(\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/symbolicregressor.py\u001b[0m in \u001b[0;36m_mse_loss\u001b[0;34m(self, model_in, target)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;31m#model_in = model_in.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m#target = target.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mpred_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m#return F.mse_loss(pred_mean, target, reduction=\"none\").sum((1, 2)).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/symbolicregressor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, rng, **args)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/symbolicregressor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mYs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research_2/mbrl-lib/mbrl/models/utils_symbolicregressor.py\u001b[0m in \u001b[0;36mwrapped_numexpr_fn\u001b[0;34m(_infix, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"X{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_infix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mlocal_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_infix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srbench/lib/python3.7/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0m_names_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpr_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetExprNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_uses_vml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_names_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpr_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m     \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;31m# Create a signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/srbench/lib/python3.7/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mgetArguments\u001b[0;34m(names, local_dict, global_dict)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X0'"
     ]
    }
   ],
   "source": [
    "dynamics_model.update_normalizer(train_replay_buffer.get_all())  # update normalizer stats\n",
    "#dynamics_model.model.reset_models()\n",
    "\n",
    "dataset_train, _ = common_util.get_basic_buffer_iterators(\n",
    "    train_replay_buffer,\n",
    "    batch_size=cfg.overrides.model_batch_size,\n",
    "    val_ratio=cfg.overrides.validation_ratio\n",
    ")\n",
    "dataset_eval, _ = common_util.get_basic_buffer_iterators(\n",
    "    eval_replay_buffer,\n",
    "    batch_size=cfg.overrides.model_batch_size,\n",
    "    val_ratio=cfg.overrides.validation_ratio,\n",
    ")\n",
    "\n",
    "model_trainer.train(\n",
    "    dataset_train=dataset_train, \n",
    "    dataset_val=dataset_eval,\n",
    "    callback=train_callback,\n",
    "    num_epochs=5000, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.140768419230512*X0 + 0.361488399541931*sqrt(5)*X0 + 0.0743721257570055*X1 - 9.70025430067247e-10\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "expr = Add(Mul(Float('0.14076841923051173', precision=53), Symbol('X0')), Mul(Float('0.36148839954193146', precision=53), Pow(Integer(5), Rational(1, 2)), Symbol('X0')), Mul(Float('0.074372125757005525', precision=53), Symbol('X1')), Float('-9.7002543006724722e-10', precision=53))\n",
    "print(str(expr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiDimensionalRegressorWrapper' object has no attribute 'get_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_393948/861660849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obs_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/srbench/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1186\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiDimensionalRegressorWrapper' object has no attribute 'get_functions'"
     ]
    }
   ],
   "source": [
    "fns = model_trainer.model.model.get_functions(env.get_obs_names() + [\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics_model.update_normalizer(train_replay_buffer.get_all())  # update normalizer stats\n",
    "\n",
    "dataset_train, _ = common_util.get_basic_buffer_iterators(\n",
    "    train_replay_buffer,\n",
    "    batch_size=cfg.overrides.model_batch_size,\n",
    "    val_ratio=cfg.overrides.validation_ratio\n",
    ")\n",
    "dataset_eval, _ = common_util.get_basic_buffer_iterators(\n",
    "    eval_replay_buffer,\n",
    "    batch_size=cfg.overrides.model_batch_size,\n",
    "    val_ratio=cfg.overrides.validation_ratio,\n",
    ")\n",
    "\n",
    "model_trainer.train(\n",
    "    dataset_train=dataset_train, \n",
    "    dataset_val=dataset_eval,\n",
    "    num_epochs=50, \n",
    "    patience=50, \n",
    "    callback=train_callback,\n",
    "    silent=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now populate the replay buffer with random trajectories of a desired length, using a single function call to `util.rollout_agent_trajectories`. Note that we pass an agent of type `planning.RandomAgent` to generate the actions; however, this method accepts any agent that is a subclass of `planning.Agent`, allowing changing exploration strategies with minimal changes to the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEM Agent\n",
    "\n",
    "The following config object and the subsequent function call create an agent that can plan using the Cross-Entropy Method over the model environment created above. When calling `planning.create_trajectory_optim_agent_for_model`, we also specify how many particles to use when propagating model uncertainty, as well as the uncertainty propagation method, \"fixed_model\", which corresponds to the method TS$\\infty$ in the PETS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_cfg = omegaconf.OmegaConf.create({\n",
    "    # this class evaluates many trajectories and picks the best one\n",
    "    \"_target_\": \"mbrl.planning.TrajectoryOptimizerAgent\",\n",
    "    \"planning_horizon\": 15,\n",
    "    \"replan_freq\": 1,\n",
    "    \"verbose\": False,\n",
    "    \"action_lb\": \"???\",\n",
    "    \"action_ub\": \"???\",\n",
    "    # this is the optimizer to generate and choose a trajectory\n",
    "    \"optimizer_cfg\": {\n",
    "        \"_target_\": \"mbrl.planning.CEMOptimizer\",\n",
    "        \"num_iterations\": 5,\n",
    "        \"elite_ratio\": 0.1,\n",
    "        \"population_size\": 500,\n",
    "        \"alpha\": 0.1,\n",
    "        \"device\": device,\n",
    "        \"lower_bound\": \"???\",\n",
    "        \"upper_bound\": \"???\",\n",
    "        \"return_mean_elites\": True,\n",
    "        \"clipped_normal\": False\n",
    "    }\n",
    "})\n",
    "\n",
    "agent = planning.create_trajectory_optim_agent_for_model(\n",
    "    model_env,\n",
    "    agent_cfg,\n",
    "    num_particles=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running PETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a model and an agent, we can now run PETS with a simple loop and a few function calls. The first code block creates a callback to pass to the model trainer to accumulate the training losses and validation scores observed. The second block is just a utility function to update the agent's visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_axes(_axs, _frame, _text, _trial, _steps_trial, _all_rewards, force_update=False):\n",
    "    if not force_update and (_steps_trial % 10 != 0):\n",
    "        return\n",
    "    _axs[0].imshow(_frame)\n",
    "    _axs[0].set_xticks([])\n",
    "    _axs[0].set_yticks([])\n",
    "    _axs[1].clear()\n",
    "    _axs[1].set_xlim([0, num_trials + .1])\n",
    "    _axs[1].set_ylim([0, 200])\n",
    "    _axs[1].set_xlabel(\"Trial\")\n",
    "    _axs[1].set_ylabel(\"Trial reward\")\n",
    "    _axs[1].plot(_all_rewards, 'bs-')\n",
    "    _text.set_text(f\"Trial {_trial + 1}: {_steps_trial} steps\")\n",
    "    plt.show()\n",
    "    \n",
    "    #display.display(plt.gcf())  \n",
    "    #display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines implement the PETS algorithm. First, we create a model trainer and pass some hyperparameters for the optimizer (Adam), along with references to the model instance to use. Then we start a loop where we execute actions of ``agent`` in the environment and train the model at the beginning of the episode (by calling ``model_trainer.train()``. At every step in the loop, we execute an agent action in the environment and populate the replay buffer by calling ``util.step_env_and_add_to_buffer()``. Importantly, at the beginning of each episode we also call ``agent.reset()`` to clear any episode dependent cache; in the case of a ``TrajectoryOptimizerAgent``, this means clearing the previous action sequence found, which is shifted at every call to obtain an initial solution for the optimizer. \n",
    "\n",
    "The rest of the code is mostly bookkeeping to keep track of the total reward observed during each episode, and to make sure episodes terminate after some desired length. After running this code, you should see the agent reaching the maximum reward of 200 after a few episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a trainer for the model\n",
    "\n",
    "# Create visualization objects\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "ax_text = axs[0].text(300, 50, \"\")\n",
    "    \n",
    "# Main PETS loop\n",
    "all_rewards = [0]\n",
    "for trial in range(num_trials):\n",
    "    obs = env.reset()    \n",
    "    agent.reset()\n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    steps_trial = 0\n",
    "    #update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards)\n",
    "    while not done:\n",
    "        # --------------- Model Training -----------------\n",
    "        if steps_trial == 0:\n",
    "            dynamics_model.model.reset_regressors()\n",
    "            dynamics_model.update_normalizer(replay_buffer.get_all())  # update normalizer stats\n",
    "            \n",
    "            dataset_train, dataset_val = common_util.get_train_test_datasets(\n",
    "                replay_buffer,\n",
    "                val_ratio=cfg.overrides.validation_ratio,\n",
    "            )\n",
    "\n",
    "            model_trainer.train(\n",
    "                dataset_train=dataset_train, \n",
    "                dataset_val=dataset_val,\n",
    "                callback=lambda train_score, eval_score: \"train: {}, eval: {}\".format(train_score, eval_score)\n",
    "                )\n",
    "\n",
    "        # --- Doing env step using the agent and adding to model dataset ---\n",
    "        next_obs, reward, done, _ = common_util.step_env_and_add_to_buffer(\n",
    "            env, obs, agent, {}, replay_buffer)\n",
    "        #update_axes(\n",
    "        #    axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards)\n",
    "        \n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        steps_trial += 1\n",
    "        \n",
    "        if steps_trial == trial_length:\n",
    "            break\n",
    "    print(total_reward)\n",
    "    all_rewards.append(total_reward)\n",
    "\n",
    "update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards, force_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below we check the results of the trainer callback, which show the training loss and validation score across all calls to ``model_trainer.train()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].set_xlabel(\"Total training epochs\")\n",
    "ax[0].set_ylabel(\"Training loss (avg. NLL)\")\n",
    "ax[1].plot(val_scores)\n",
    "ax[1].set_xlabel(\"Total training epochs\")\n",
    "ax[1].set_ylabel(\"Validation score (avg. MSE)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to learn more about MBRL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about the other features of the library, please check out our [documentation](https://facebookresearch.github.io/mbrl-lib/). Also take a look at our provided implementations of [PETS](https://github.com/facebookresearch/mbrl-lib/blob/main/mbrl/algorithms/pets.py), [MBPO](https://github.com/facebookresearch/mbrl-lib/blob/main/mbrl/algorithms/mbpo.py), and [PlaNet](https://github.com/facebookresearch/mbrl-lib/blob/main/mbrl/algorithms/planet.py), and their configuration [files](https://github.com/facebookresearch/mbrl-lib/tree/main/mbrl/examples/conf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "text = \"(-nan + (1.000 * cos((sin(((-0.923) * X2)) - ((sin((((-0.477) * X2) / 0.546)) + ((((-1.958) * X5) ** ((-1.167) * X3)) * ((-0.574) * X4))) + ((1.897 * X4) * (sin(((-0.459) * X4)) - ((-0.257) * X1))))))))\"\n",
    "expr = sp.parse_expr(text)\n",
    "print(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbrl.models.symbolicregressor import expr_to_torch_module\n",
    "expr_to_torch_module(expr, \"cuda\")(torch.tensor([[1.,2]]).to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5eb44a93f6b3e6b2258cfef6e52b67f2b1256f4b50ffc36e5573a6b49b83ee11"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
